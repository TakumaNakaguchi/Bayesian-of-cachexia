{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TakumaNakaguchi/Bayesian-of-cachexia/blob/main/%E8%A8%AA%E5%95%8F%E3%83%AA%E3%83%8F%E5%8A%B9%E6%9E%9C%E3%81%AE%E9%9A%8E%E5%B1%A4%E3%83%99%E3%82%A4%E3%82%BA%E3%83%A2%E3%83%87%E3%83%AB%E8%A7%A3%E6%9E%90%E3%82%B3%E3%83%BC%E3%83%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ライブラリのインストール（Google Colabで初回実行時のみ必要）\n",
        "# =============================================================================\n",
        "# !pip install pymc==5.10.3 arviz==0.17.0 pandas==2.1.4 numpy==1.26.2 matplotlib==3.8.2 seaborn==0.13.1\n",
        "\n",
        "# =============================================================================\n",
        "# ライブラリのインポート\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "print(f\"PyMC Version: {pm.__version__}\")\n",
        "print(f\"ArviZ Version: {az.__version__}\")\n",
        "\n",
        "# =============================================================================\n",
        "# Part 1: 仮想データの生成と準備\n",
        "# =============================================================================\n",
        "# 論文の記述に基づき、仮想データを生成します。\n",
        "# 実際のデータを使用する場合は、このセクションをコメントアウトし、\n",
        "# 次の「実際のデータ読み込み」セクションを使用してください。\n",
        "\n",
        "# シードを設定して再現性を確保\n",
        "np.random.seed(42)\n",
        "\n",
        "# 対象者数\n",
        "n_patients = 49\n",
        "\n",
        "# 論文の表1、表2に基づき、各変数の関係性を考慮して仮想データを生成\n",
        "# 相関行列を定義（探索的解析の結果を参考に設定）\n",
        "# Variables: age, bmi, grip, ftsst, crp, mmse, bi_initial, bi_gain\n",
        "corr_matrix = np.array([\n",
        "    [1.00, 0.10, -0.30, 0.40, 0.30, -0.30, -0.20, -0.25], # age\n",
        "    [0.10, 1.00, 0.20, 0.10, 0.15, -0.10, 0.10, -0.21], # bmi\n",
        "    [0.10, 0.20, 1.00, -0.30, -0.20, 0.20, 0.30, 0.10], # grip\n",
        "    [0.40, 0.10, -0.30, 1.00, 0.25, -0.40, -0.30, -0.22], # ftsst\n",
        "    [0.30, 0.15, -0.20, 0.25, 1.00, -0.20, -0.20, -0.19], # crp\n",
        "    [-0.30, -0.10, 0.20, -0.40, -0.20, 1.00, 0.30, 0.18], # mmse\n",
        "    [-0.20, 0.10, 0.30, -0.30, -0.20, 0.30, 1.00, -0.10], # bi_initial\n",
        "    [-0.25, -0.21, 0.10, -0.22, -0.19, 0.18, -0.10, 1.00]  # bi_gain\n",
        "])\n",
        "\n",
        "# 平均と標準偏差\n",
        "means = np.array([84.5, 19.9, 17.0, 35.8, 3.26, 24.8, 67.7, 13.8]) # bi_gainの平均はbi_6m - bi_initialから算出\n",
        "stds = np.array([7.8, 4.7, 4.0, 8.4, 6.89, 4.8, 16.1, 15.0]) # bi_gainのSDは仮定\n",
        "\n",
        "# 多変量正規分布に従うデータを生成\n",
        "data = np.random.multivariate_normal(means, np.diag(stds) @ corr_matrix @ np.diag(stds), n_patients)\n",
        "\n",
        "df = pd.DataFrame(data, columns=['age', 'bmi', 'grip', 'ftsst', 'crp', 'mmse', 'bi_initial', 'bi_gain_temp'])\n",
        "\n",
        "# カテゴリ変数の生成\n",
        "# 性別 (女性=1, 男性=0): 75.5%が女性\n",
        "df['sex'] = np.random.choice([1, 0], n_patients, p=[0.755, 0.245])\n",
        "# 訪問リハ頻度 (週2回以上=1, 週1回=0): 40.9%が週2回以上\n",
        "df['rehab_freq'] = np.random.choice([1, 0], n_patients, p=[0.409, 0.591])\n",
        "# 住居環境 (施設=1, 自宅=0): 44.9%が施設\n",
        "df['residence'] = np.random.choice([1, 0], n_patients, p=[0.449, 0.551])\n",
        "\n",
        "# 生成したデータの値を論文の範囲に収めるように調整\n",
        "df['age'] = np.clip(df['age'], 65, 100).astype(int)\n",
        "df['bmi'] = np.clip(df['bmi'], 12, 30)\n",
        "df['grip'] = np.clip(df['grip'], 5, 30)\n",
        "df['ftsst'] = np.clip(df['ftsst'], 15, 60)\n",
        "df['crp'] = np.clip(df['crp'], 0.1, 30)\n",
        "df['mmse'] = np.clip(df['mmse'], 10, 30).astype(int)\n",
        "df['bi_initial'] = np.clip(df['bi_initial'], 0, 100).astype(int)\n",
        "df['bi_6months'] = np.clip(df['bi_initial'] + df['bi_gain_temp'], 0, 100).astype(int)\n",
        "df['bi_gain'] = df['bi_6months'] - df['bi_initial']\n",
        "\n",
        "# 不要な列を削除\n",
        "df = df.drop(columns=['bi_gain_temp'])\n",
        "\n",
        "print(\"--- 生成された仮想データの基本統計量 ---\")\n",
        "print(df.describe())\n",
        "print(\"\\n--- カテゴリ変数の分布 ---\")\n",
        "print(df[['sex', 'rehab_freq', 'residence']].apply(pd.Series.value_counts))\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 実際のデータ読み込み（このセクションはコメントアウトされています）\n",
        "# =============================================================================\n",
        "# # CSVファイルなどから実際のデータを読み込む場合は、以下のコードを使用してください。\n",
        "# # ファイルパスは適宜変更してください。\n",
        "# try:\n",
        "#     df = pd.read_csv('your_data.csv')\n",
        "#     # 論文に合わせて列名を変更\n",
        "#     # df.columns = ['age', 'sex', 'bmi', 'rehab_freq', 'residence',\n",
        "#     #               'bi_initial', 'bi_6months', 'grip', 'ftsst', 'crp', 'mmse']\n",
        "#     # BI利得を計算\n",
        "#     # df['bi_gain'] = df['bi_6months'] - df['bi_initial']\n",
        "#     print(\"--- 実際のデータを読み込みました ---\")\n",
        "# except FileNotFoundError:\n",
        "#     print(\"--- your_data.csv が見つかりません。仮想データを引き続き使用します。 ---\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# データの前処理：変数の標準化\n",
        "# =============================================================================\n",
        "# 連続変数を標準化（平均0, 標準偏差1）します。\n",
        "# これにより、モデルの収束が改善され、係数の解釈が容易になります。\n",
        "continuous_vars = ['age', 'bmi', 'grip', 'ftsst', 'crp', 'mmse', 'bi_initial']\n",
        "categorical_vars = ['sex', 'rehab_freq', 'residence']\n",
        "\n",
        "# 標準化前の統計量を保存\n",
        "means_std = df[continuous_vars].mean()\n",
        "stds_std = df[continuous_vars].std()\n",
        "\n",
        "# 標準化\n",
        "df_std = df.copy()\n",
        "for var in continuous_vars:\n",
        "    df_std[var] = (df[var] - means_std[var]) / stds_std[var]\n",
        "\n",
        "print(\"\\n--- データの前処理が完了しました ---\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Part 2: 主解析 - 階層ベイズモデル\n",
        "# =============================================================================\n",
        "# 論文の主解析モデルを構築し、MCMCサンプリングを実行します。\n",
        "# 従属変数: BI利得 (bi_gain)\n",
        "# 説明変数: bi_initial, age, sex, bmi, rehab_freq, residence, grip, ftsst, crp, mmse\n",
        "\n",
        "coords = {\"coeffs\": ['bi_initial', 'age', 'sex', 'bmi', 'rehab_freq', 'residence', 'grip', 'ftsst', 'crp', 'mmse']}\n",
        "\n",
        "with pm.Model(coords=coords) as main_model:\n",
        "    # --- 事前分布の設定 ---\n",
        "    # 切片 (Intercept): 先行研究に基づき、平均5.8, 標準偏差5.33の正規分布\n",
        "    intercept = pm.Normal('intercept', mu=5.8, sigma=5.33)\n",
        "\n",
        "    # 係数 (beta): 論文では探索的解析に基づいて情報事前分布と弱情報事前分布を使い分けていますが、\n",
        "    # ここでは一般的に使われる弱情報事前分布（平均0、標準偏差を広めにとった正規分布）を設定します。\n",
        "    # これにより、データが持つ情報をより強く反映させることができます。\n",
        "    betas = pm.Normal('betas', mu=0, sigma=10, dims=\"coeffs\")\n",
        "\n",
        "    # モデルの誤差 (sigma): 半コーシー分布\n",
        "    sigma = pm.HalfCauchy('sigma', beta=5)\n",
        "\n",
        "    # --- 線形モデルの定義 ---\n",
        "    mu = (intercept +\n",
        "          betas[0] * df_std['bi_initial'] +\n",
        "          betas[1] * df_std['age'] +\n",
        "          betas[2] * df_std['sex'] +\n",
        "          betas[3] * df_std['bmi'] +\n",
        "          betas[4] * df_std['rehab_freq'] +\n",
        "          betas[5] * df_std['residence'] +\n",
        "          betas[6] * df_std['grip'] +\n",
        "          betas[7] * df_std['ftsst'] +\n",
        "          betas[8] * df_std['crp'] +\n",
        "          betas[9] * df_std['mmse']\n",
        "         )\n",
        "\n",
        "    # --- 尤度 ---\n",
        "    # BI利得が正規分布に従うと仮定\n",
        "    bi_gain_obs = pm.Normal('bi_gain_obs', mu=mu, sigma=sigma, observed=df['bi_gain'])\n",
        "\n",
        "    # --- MCMCサンプリングの実行 ---\n",
        "    # 論文の設定に合わせて、4チェーン、2000反復（うち500をバーンイン）\n",
        "    print(\"\\n--- 主解析モデルのサンプリングを開始します ---\")\n",
        "    trace_main = pm.sample(2000, tune=500, chains=4, target_accept=0.9, random_seed=42)\n",
        "    print(\"--- サンプリングが完了しました ---\")\n",
        "\n",
        "# --- 結果の表示 ---\n",
        "print(\"\\n--- 主解析モデルの結果 ---\")\n",
        "summary_main = az.summary(trace_main, var_names=['intercept', 'betas', 'sigma'], hdi_prob=0.95, round_to=2)\n",
        "print(summary_main)\n",
        "\n",
        "# 収束診断 (R-hatが1.1未満であれば良好)\n",
        "if (summary_main['r_hat'] > 1.1).any():\n",
        "    print(\"\\n警告: いくつかのパラメータで収束に問題がある可能性があります (R-hat > 1.1)。\")\n",
        "else:\n",
        "    print(\"\\nすべてのパラメータで収束を確認しました (R-hat < 1.1)。\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Part 3: 層別解析 - 訪問リハビリテーション頻度別のBI利得\n",
        "# =============================================================================\n",
        "# 主解析モデルの結果を用いて、訪問リハ頻度別のBI利得の事後分布を計算・可視化します。\n",
        "\n",
        "# 他の変数を平均値（標準化後データでは0）に固定した場合のBI利得を計算\n",
        "posterior = trace_main.posterior\n",
        "intercept_samples = posterior['intercept'].values.flatten()\n",
        "rehab_freq_beta_samples = posterior['betas'].sel(coeffs='rehab_freq').values.flatten()\n",
        "\n",
        "# 週1回群 (rehab_freq=0) のBI利得\n",
        "# rehab_freq=0は標準化すると負の値になるため、標準化前の値で計算\n",
        "rehab_freq_0_std = (0 - means_std['rehab_freq']) / stds_std['rehab_freq']\n",
        "gain_weekly = intercept_samples + rehab_freq_beta_samples * rehab_freq_0_std\n",
        "\n",
        "# 週2回以上群 (rehab_freq=1) のBI利得\n",
        "rehab_freq_1_std = (1 - means_std['rehab_freq']) / stds_std['rehab_freq']\n",
        "gain_biweekly = intercept_samples + rehab_freq_beta_samples * rehab_freq_1_std\n",
        "\n",
        "print(\"\\n--- 層別解析の結果 ---\")\n",
        "print(f\"週1回群のBI利得（事後平均）: {gain_weekly.mean():.2f} (95%信用区間: {np.quantile(gain_weekly, 0.025):.2f} - {np.quantile(gain_weekly, 0.975):.2f})\")\n",
        "print(f\"週2回以上群のBI利得（事後平均）: {gain_biweekly.mean():.2f} (95%信用区間: {np.quantile(gain_biweekly, 0.025):.2f} - {np.quantile(gain_biweekly, 0.975):.2f})\")\n",
        "\n",
        "# --- 結果の可視化 ---\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.kdeplot(gain_weekly, ax=ax, label='Weekly Rehab (週1回)', fill=True)\n",
        "sns.kdeplot(gain_biweekly, ax=ax, label='Bi-weekly+ Rehab (週2回以上)', fill=True)\n",
        "ax.set_title('Posterior Distribution of BI Gain by Rehab Frequency (訪問リハ頻度別BI利得の事後分布)', fontsize=16)\n",
        "ax.set_xlabel('Estimated BI Gain (推定BI利得)', fontsize=12)\n",
        "ax.set_ylabel('Density (密度)', fontsize=12)\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Part 4: 感度解析\n",
        "# =============================================================================\n",
        "# 論文で述べられている3つの感度解析を実施し、結果の頑健性を確認します。\n",
        "\n",
        "# --- ① BI利得の事前分布変更 ---\n",
        "# 切片の事前分布の標準偏差をMDCである16.3に変更\n",
        "with pm.Model(coords=coords) as sensitivity_model_1:\n",
        "    intercept = pm.Normal('intercept', mu=5.8, sigma=16.3) # 標準偏差を変更\n",
        "    betas = pm.Normal('betas', mu=0, sigma=10, dims=\"coeffs\")\n",
        "    sigma = pm.HalfCauchy('sigma', beta=5)\n",
        "    mu = (intercept + pm.math.dot(df_std[coords['coeffs']].values, betas))\n",
        "    bi_gain_obs = pm.Normal('bi_gain_obs', mu=mu, sigma=sigma, observed=df['bi_gain'])\n",
        "\n",
        "    print(\"\\n--- 感度解析① (事前分布変更) のサンプリングを開始します ---\")\n",
        "    trace_sens_1 = pm.sample(2000, tune=500, chains=4, random_seed=42)\n",
        "    print(\"--- サンプリングが完了しました ---\")\n",
        "\n",
        "print(\"\\n--- 感度解析① の結果 ---\")\n",
        "print(az.summary(trace_sens_1, var_names=['intercept', 'betas', 'sigma'], hdi_prob=0.95, round_to=2))\n",
        "\n",
        "\n",
        "# --- ② 総因果効果の評価 ---\n",
        "# 従属変数を6ヶ月後BI、説明変数から開始時BIを除外\n",
        "coords_total = {\"coeffs\": ['age', 'sex', 'bmi', 'rehab_freq', 'residence', 'grip', 'ftsst', 'crp', 'mmse']}\n",
        "with pm.Model(coords=coords_total) as sensitivity_model_2:\n",
        "    intercept = pm.Normal('intercept', mu=df['bi_6months'].mean(), sigma=10)\n",
        "    betas = pm.Normal('betas', mu=0, sigma=10, dims=\"coeffs\")\n",
        "    sigma = pm.HalfCauchy('sigma', beta=5)\n",
        "    mu = (intercept + pm.math.dot(df_std[coords_total['coeffs']].values, betas))\n",
        "    bi_6m_obs = pm.Normal('bi_6m_obs', mu=mu, sigma=sigma, observed=df['bi_6months'])\n",
        "\n",
        "    print(\"\\n--- 感度解析② (総因果効果) のサンプリングを開始します ---\")\n",
        "    trace_sens_2 = pm.sample(2000, tune=500, chains=4, random_seed=42)\n",
        "    print(\"--- サンプリングが完了しました ---\")\n",
        "\n",
        "print(\"\\n--- 感度解析② の結果 (訪問リハ頻度の効果に注目) ---\")\n",
        "print(az.summary(trace_sens_2, var_names=['betas'], hdi_prob=0.95, round_to=2).loc[f\"betas[{'rehab_freq'}]\"])\n",
        "\n",
        "\n",
        "# --- ③ 直接因果効果の評価 ---\n",
        "# 従属変数を6ヶ月後BI、説明変数に開始時BIを追加\n",
        "coords_direct = {\"coeffs\": ['bi_initial', 'age', 'sex', 'bmi', 'rehab_freq', 'residence', 'grip', 'ftsst', 'crp', 'mmse']}\n",
        "with pm.Model(coords=coords_direct) as sensitivity_model_3:\n",
        "    intercept = pm.Normal('intercept', mu=df['bi_6months'].mean(), sigma=10)\n",
        "    betas = pm.Normal('betas', mu=0, sigma=10, dims=\"coeffs\")\n",
        "    sigma = pm.HalfCauchy('sigma', beta=5)\n",
        "    mu = (intercept + pm.math.dot(df_std[coords_direct['coeffs']].values, betas))\n",
        "    bi_6m_obs = pm.Normal('bi_6m_obs', mu=mu, sigma=sigma, observed=df['bi_6months'])\n",
        "\n",
        "    print(\"\\n--- 感度解析③ (直接因果効果) のサンプリングを開始します ---\")\n",
        "    trace_sens_3 = pm.sample(2000, tune=500, chains=4, random_seed=42)\n",
        "    print(\"--- サンプリングが完了しました ---\")\n",
        "\n",
        "print(\"\\n--- 感度解析③ の結果 (訪問リハ頻度の効果に注目) ---\")\n",
        "print(az.summary(trace_sens_3, var_names=['betas'], hdi_prob=0.95, round_to=2).loc[f\"betas[{'rehab_freq'}]\"])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "OoAlnAOmQrdP"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}